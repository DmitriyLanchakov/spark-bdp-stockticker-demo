{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grab data from google finance api\n",
    "#Daily stock data will be grab for all tickers in tickerFile from today until lastDay\n",
    "#and written to riak bucket 'stocks'\n",
    "\n",
    "today = datetime(datetime.now().year, datetime.now().month, datetime.now().day)#todays year,month,day\n",
    "lastDay = datetime(2000,1,1)#last day to download stock data from\n",
    "tickerFile = 'NYSE.txt'#file contains all ticker,name pairs on NYSE\n",
    "dataSource = 'google'#download from 'google' or 'yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(tickerFile,sep='\\t',header=None)#read in stock ticker,name pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickers = list(stocks[0])#extract tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.64578199386597"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These operations will populate riak with data\n",
    "t0 = time.time()\n",
    "dataGet = sc.parallelize(tickers[0:100]).map(lambda x: getDataByTicker(x,dataSource,lastDay,today)).collect()#get data and write to riak for each ticker\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3893,\n",
       " 3893,\n",
       " 5,\n",
       " 183,\n",
       " 2787,\n",
       " 3415,\n",
       " 1118,\n",
       " 2400,\n",
       " 3893,\n",
       " 3575,\n",
       " 639,\n",
       " 3893,\n",
       " 407,\n",
       " 3344,\n",
       " 3893,\n",
       " 2823,\n",
       " 601,\n",
       " 536,\n",
       " 336,\n",
       " 0,\n",
       " 3893,\n",
       " 3893,\n",
       " 2736,\n",
       " 2483,\n",
       " 3893,\n",
       " 3893,\n",
       " 3407,\n",
       " 3893,\n",
       " 2046,\n",
       " 3504,\n",
       " 1109,\n",
       " 795,\n",
       " 0,\n",
       " 8,\n",
       " 23,\n",
       " 1190,\n",
       " 3893,\n",
       " 3893,\n",
       " 252,\n",
       " 3532,\n",
       " 696,\n",
       " 3893,\n",
       " 2391,\n",
       " 3893,\n",
       " 2391,\n",
       " 3893,\n",
       " 3893,\n",
       " 2524,\n",
       " 0,\n",
       " 2908,\n",
       " 3893,\n",
       " 3893,\n",
       " 3893,\n",
       " 2161,\n",
       " 3893,\n",
       " 3893,\n",
       " 3893,\n",
       " 3893,\n",
       " 4,\n",
       " 0,\n",
       " 3375,\n",
       " 2063,\n",
       " 3893,\n",
       " 0,\n",
       " 3893,\n",
       " 0,\n",
       " 1191,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1090,\n",
       " 0,\n",
       " 3485,\n",
       " 2035,\n",
       " 3121,\n",
       " 2244,\n",
       " 2932,\n",
       " 3893,\n",
       " 605,\n",
       " 4,\n",
       " 220,\n",
       " 3794,\n",
       " 2812,\n",
       " 1317,\n",
       " 1317,\n",
       " 1317,\n",
       " 1108,\n",
       " 3893,\n",
       " 3892,\n",
       " 1869,\n",
       " 537,\n",
       " 2908,\n",
       " 2162,\n",
       " 805,\n",
       " 538,\n",
       " 410,\n",
       " 3426,\n",
       " 2978,\n",
       " 2693]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataGet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful delete: AGCO_AGM\n",
      "Successful delete: AET_AGI\n",
      "Successful delete: AET_ACH\n",
      "Successful delete: AAP_AEM\n",
      "Successful delete: AAP_AB\n",
      "Successful delete: AF_AFB\n",
      "Successful delete: AAP_AEO\n",
      "Successful delete: AGCO_AGI\n",
      "Successful delete: ABG_AGI\n",
      "Successful delete: AAP_ABC\n",
      "Successful delete: AHS_AGC\n",
      "Successful delete: AET_AGC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.94734597206116"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minVol = 20000#minimum volatilty to filter on\n",
    "minDays = 2000#minimum amount of data points needed\n",
    "zThresh = 2\n",
    "beginDay = 0\n",
    "ndays = 100\n",
    "critLevel = '5%' #can be '1%', '5%', or '10%'\n",
    "delKeys = deleteAllKeys('tradeEntries')\n",
    "#Gather the data into rdd and transform so that pairAnalysis can be run on each pair of stocks\n",
    "\n",
    "#Spark \n",
    "#1:For each ticker we grab the data from riak using riakGetStock\n",
    "#2:Filter out ticker,data pairs that have less than minDays worth of data\n",
    "#3:Filter out all ticker,data pairs that have a mean volatility less than minVol\n",
    "#4:Sort each tickers,data pairs data by date with most recent data at the beginning of the array using mySort\n",
    "#5:Cut all ticker,data pairs data to be of length minDays using myFilter and cache the rdd in memory\n",
    "\n",
    "t0 = time.time()#time begin\n",
    "d = sc.parallelize(tickers[0:100]).map(lambda x: (x, riakGetStock(x)))\\\n",
    "    .filter(lambda x: len(x[1]) > minDays)\\\n",
    "    .filter(lambda x: numpy.mean([i[1] for i in x[1]]) > minVol)\\\n",
    "    .map(lambda x: (x[0],mySort(x[1])))\\\n",
    "    .map(lambda x: (x[0],myFilter(x[1],minDays))).cache()\n",
    "\n",
    "#Analyze all stock pairs and return the results    \n",
    "    \n",
    "#Spark    \n",
    "#from the cahced rdd d create a cartesian product of all possible ticker pairs\n",
    "#then for each ticker pair run pairAnalysis which returns either a number or a list of values\n",
    "#collect the rdd\n",
    "\n",
    "pairs = d.cartesian(d)\\\n",
    "    .map(lambda x: pairAnalysis(x,ndays,beginDay,zThresh))\\\n",
    "    .filter(lambda x: type(x) is list)\\\n",
    "    .map(lambda x: writeSinglePair(x))\\\n",
    "    .cache().collect()\n",
    "t1 = time.time()#time end\n",
    "\n",
    "total = t1-t0\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AAP',\n",
       "  'AB',\n",
       "  '2015-06-23',\n",
       "  163.89,\n",
       "  30.0,\n",
       "  2.0325065800785458,\n",
       "  -0.92833169871411769,\n",
       "  -1.179614628199488e-13,\n",
       "  5.6997511318368153],\n",
       " ['AAP',\n",
       "  'ABC',\n",
       "  '2015-06-23',\n",
       "  163.89,\n",
       "  111.81,\n",
       "  2.1268201231154578,\n",
       "  -0.37135467337889794,\n",
       "  6.1936589190736407e-14,\n",
       "  5.7942745656899959],\n",
       " ['AAP',\n",
       "  'AEM',\n",
       "  '2015-06-23',\n",
       "  163.89,\n",
       "  30.1,\n",
       "  2.1993243517763457,\n",
       "  0.9659809460300588,\n",
       "  1.1250449460931123e-13,\n",
       "  5.5689604525184668],\n",
       " ['AAP',\n",
       "  'AEO',\n",
       "  '2015-06-23',\n",
       "  163.89,\n",
       "  17.77,\n",
       "  2.449653665451744,\n",
       "  -1.5470843605914886,\n",
       "  3.8962753023952246e-13,\n",
       "  5.5651553786213874],\n",
       " ['ABG',\n",
       "  'AGI',\n",
       "  '2015-06-23',\n",
       "  92.14,\n",
       "  5.84,\n",
       "  2.2281646250866216,\n",
       "  4.5407296405716675,\n",
       "  1.2551026884466409e-14,\n",
       "  4.8757504685847444],\n",
       " ['AET',\n",
       "  'ACH',\n",
       "  '2015-06-23',\n",
       "  128.2,\n",
       "  13.16,\n",
       "  2.3481449968304062,\n",
       "  2.1464193559242299,\n",
       "  -2.4738255888223647e-14,\n",
       "  9.2004750163219349],\n",
       " ['AF',\n",
       "  'AFB',\n",
       "  '2015-06-23',\n",
       "  14.02,\n",
       "  13.42,\n",
       "  2.1323444361678949,\n",
       "  -0.65921620714302764,\n",
       "  2.9956481739645822e-15,\n",
       "  0.38383105129421424],\n",
       " ['AET',\n",
       "  'AGC',\n",
       "  '2015-06-23',\n",
       "  128.2,\n",
       "  6.71,\n",
       "  2.187866668379316,\n",
       "  31.418158142615987,\n",
       "  -3.7107383832335475e-14,\n",
       "  9.4762745311027494],\n",
       " ['AET',\n",
       "  'AGI',\n",
       "  '2015-06-23',\n",
       "  128.2,\n",
       "  5.84,\n",
       "  2.6085495204715476,\n",
       "  6.6130983981413287,\n",
       "  -6.3300831243395801e-14,\n",
       "  8.849823360848422],\n",
       " ['AGCO',\n",
       "  'AGI',\n",
       "  '2015-06-23',\n",
       "  55.07,\n",
       "  5.84,\n",
       "  2.8649821233277368,\n",
       "  1.5785332051119714,\n",
       "  4.1609382606111468e-15,\n",
       "  2.1554589970704736],\n",
       " ['AGCO',\n",
       "  'AGM',\n",
       "  '2015-06-23',\n",
       "  55.07,\n",
       "  30.48,\n",
       "  2.7244846509872853,\n",
       "  0.67808092154803157,\n",
       "  -4.206412995699793e-14,\n",
       "  2.2202805424296046],\n",
       " ['AHS',\n",
       "  'AGC',\n",
       "  '2015-06-23',\n",
       "  30.54,\n",
       "  6.71,\n",
       "  2.1252132439631657,\n",
       "  9.5011968655782599,\n",
       "  -2.0918378140777349e-15,\n",
       "  3.1553367849693568]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAP_AB': '{\"CloseB\": 30.0, \"ZScore\": 2.0325065800785458, \"CloseA\": 163.89, \"SignalMean\": -1.179614628199488e-13, \"SignalSD\": 5.6997511318368153, \"Date\": \"2015-06-23\", \"StockA\": \"AAP\", \"StockB\": \"AB\", \"Beta\": -0.92833169871411769}',\n",
       " 'AAP_ABC': '{\"CloseB\": 111.81, \"ZScore\": 2.1268201231154578, \"CloseA\": 163.89, \"SignalMean\": 6.1936589190736407e-14, \"SignalSD\": 5.7942745656899959, \"Date\": \"2015-06-23\", \"StockA\": \"AAP\", \"StockB\": \"ABC\", \"Beta\": -0.37135467337889794}',\n",
       " 'AAP_AEM': '{\"CloseB\": 30.1, \"ZScore\": 2.1993243517763457, \"CloseA\": 163.89, \"SignalMean\": 1.1250449460931123e-13, \"SignalSD\": 5.5689604525184668, \"Date\": \"2015-06-23\", \"StockA\": \"AAP\", \"StockB\": \"AEM\", \"Beta\": 0.9659809460300588}',\n",
       " 'AAP_AEO': '{\"CloseB\": 17.77, \"ZScore\": 2.449653665451744, \"CloseA\": 163.89, \"SignalMean\": 3.8962753023952246e-13, \"SignalSD\": 5.5651553786213874, \"Date\": \"2015-06-23\", \"StockA\": \"AAP\", \"StockB\": \"AEO\", \"Beta\": -1.5470843605914886}',\n",
       " 'ABG_AGI': '{\"CloseB\": 5.84, \"ZScore\": 2.2281646250866216, \"CloseA\": 92.14, \"SignalMean\": 1.2551026884466409e-14, \"SignalSD\": 4.8757504685847444, \"Date\": \"2015-06-23\", \"StockA\": \"ABG\", \"StockB\": \"AGI\", \"Beta\": 4.5407296405716675}',\n",
       " 'AET_ACH': '{\"CloseB\": 13.16, \"ZScore\": 2.3481449968304062, \"CloseA\": 128.2, \"SignalMean\": -2.4738255888223647e-14, \"SignalSD\": 9.2004750163219349, \"Date\": \"2015-06-23\", \"StockA\": \"AET\", \"StockB\": \"ACH\", \"Beta\": 2.1464193559242299}',\n",
       " 'AET_AGC': '{\"CloseB\": 6.71, \"ZScore\": 2.187866668379316, \"CloseA\": 128.2, \"SignalMean\": -3.7107383832335475e-14, \"SignalSD\": 9.4762745311027494, \"Date\": \"2015-06-23\", \"StockA\": \"AET\", \"StockB\": \"AGC\", \"Beta\": 31.418158142615987}',\n",
       " 'AET_AGI': '{\"CloseB\": 5.84, \"ZScore\": 2.6085495204715476, \"CloseA\": 128.2, \"SignalMean\": -6.3300831243395801e-14, \"SignalSD\": 8.849823360848422, \"Date\": \"2015-06-23\", \"StockA\": \"AET\", \"StockB\": \"AGI\", \"Beta\": 6.6130983981413287}',\n",
       " 'AF_AFB': '{\"CloseB\": 13.42, \"ZScore\": 2.1323444361678949, \"CloseA\": 14.02, \"SignalMean\": 2.9956481739645822e-15, \"SignalSD\": 0.38383105129421424, \"Date\": \"2015-06-23\", \"StockA\": \"AF\", \"StockB\": \"AFB\", \"Beta\": -0.65921620714302764}',\n",
       " 'AGCO_AGI': '{\"CloseB\": 5.84, \"ZScore\": 2.8649821233277368, \"CloseA\": 55.07, \"SignalMean\": 4.1609382606111468e-15, \"SignalSD\": 2.1554589970704736, \"Date\": \"2015-06-23\", \"StockA\": \"AGCO\", \"StockB\": \"AGI\", \"Beta\": 1.5785332051119714}',\n",
       " 'AGCO_AGM': '{\"CloseB\": 30.48, \"ZScore\": 2.7244846509872853, \"CloseA\": 55.07, \"SignalMean\": -4.206412995699793e-14, \"SignalSD\": 2.2202805424296046, \"Date\": \"2015-06-23\", \"StockA\": \"AGCO\", \"StockB\": \"AGM\", \"Beta\": 0.67808092154803157}',\n",
       " 'AHS_AGC': '{\"CloseB\": 6.71, \"ZScore\": 2.1252132439631657, \"CloseA\": 30.54, \"SignalMean\": -2.0918378140777349e-15, \"SignalSD\": 3.1553367849693568, \"Date\": \"2015-06-23\", \"StockA\": \"AHS\", \"StockB\": \"AGC\", \"Beta\": 9.5011968655782599}'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAllKV('tradeEntries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import time\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import riak\n",
    "import urllib2\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from pandas.io.data import DataReader\n",
    "import riak\n",
    "from riak import RiakClient, RiakNode, RiakObject\n",
    "import numpy as np\n",
    "import statsmodels.api as stat\n",
    "import statsmodels.tsa.stattools as ts\n",
    "\n",
    "#start is furthest day back and end is most recent day.  Grabs all data in between and stores in riak as json\n",
    "#runs through a file of ticker values\n",
    "def getData(tickerFile, dataSource, start, end):\n",
    "\n",
    "    rc = RiakClient(pb_port=8087, protocol='pbc')#set up riak connection\n",
    "    added = []#list of successful adds\n",
    "    notAdded = []#list of unsuccessful adds\n",
    "    stock = pd.read_csv(tickerFile,sep='\\t',header=None)#read in stock tickers\n",
    "\n",
    "    #loop over all stock tickers\n",
    "    for i in range(0,len(stock.head(100))):\n",
    "        \n",
    "        ticker = stock.ix[i,0]\n",
    "        if getDataByTicker(ticker,dataSource,start,end) == 0:\n",
    "            notAdded.append(ticker)\n",
    "        else:\n",
    "            added.append(ticker)\n",
    "    return added, notAdded\n",
    "\n",
    "#start is furthest day back and end is closest to today, Store single stock data in riak\n",
    "#only grabs one stock\n",
    "def getDataByTicker(ticker, dataSource, start, end):\n",
    "\n",
    "    rc = RiakClient(pb_port=8087, protocol='pbc')\n",
    "    #get daily data for each ticker\n",
    "    gtemp = pd.DataFrame()\n",
    "    bucket = rc.bucket('stocks')\n",
    "    try:\n",
    "        gtemp = DataReader(ticker,  dataSource, start, end)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        #didnt get any data\n",
    "    if len(gtemp) == 0:\n",
    "        return 0\n",
    "    #got data\n",
    "    else:\n",
    "        \n",
    "        for j in range(0,len(gtemp.index)):\n",
    "            \n",
    "            #upload json to Riak Bucket\n",
    "            date = gtemp.index[j].date()\n",
    "            riakKey = str(ticker + '_' + str(date))\n",
    "            riakVal = {'OPEN': gtemp.values[j,0],\\\n",
    "                        'HIGH': gtemp.values[j,1],\\\n",
    "                        'LOW': gtemp.values[j,2], \\\n",
    "                        'CLOSE': gtemp.values[j,3], \\\n",
    "                        'VOLUME': gtemp.values[j,4],\\\n",
    "                        'DATE': str(date),\\\n",
    "                        'TICKER': str(ticker)}\n",
    "                \n",
    "            obj = RiakObject(rc, bucket, riakKey)\n",
    "                \n",
    "            obj.add_index(\"ticker_bin\", str(ticker))\n",
    "            obj.add_index(\"year_int\", int(date.year))\n",
    "            obj.add_index(\"month_int\", int(date.month))\n",
    "            obj.add_index(\"day_int\", int(date.day))\n",
    "                \n",
    "            obj.content_type = 'text/json'\n",
    "            #obj.data = riakVal\n",
    "            obj.data = json.dumps(riakVal)\n",
    "            obj.store()\n",
    "\n",
    "    return len(gtemp.index)\n",
    "\n",
    "#searches riak bucket via 2i query and returns a dict of the data\n",
    "def riakSearchData(searchBucket, searchTerm, searchVal1, searchVal2):\n",
    "    myData = {}#empty dict\n",
    "    myBucket = RiakClient(pb_port=8087, protocol='pbc').bucket(searchBucket)\n",
    "    #check wether 1 or 2 search terms\n",
    "    if searchVal2 != None:\n",
    "        for key in myBucket.get_index(searchTerm, searchVal1, searchVal2): #get all keys with 2i match\n",
    "            myData[key] = json.loads(myBucket.get(key).data)#store data for each key\n",
    "    else:\n",
    "        for key in myBucket.get_index(searchTerm, searchVal1):#get all keys with 2i match\n",
    "            myData[key] = json.loads(myBucket.get(key).data)#store data for each key\n",
    "    return myData\n",
    "\n",
    "#store an individual key value pair in a bucket\n",
    "def storeKV(myBucket, myKey, myVal):\n",
    "    riak.RiakClient(pb_port=8087, protocol='pbc').bucket(myBucket).new(myKey, data = myVal).store()\n",
    "    return\n",
    "\n",
    "#delete a key from a bucket, provide feedback to ensure deletion\n",
    "def deleteKey(delBucket, delKey):\n",
    "    riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).delete(delKey)\n",
    "    if riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).get(delKey).data == None:\n",
    "        print 'Successful delete: %s' % delKey\n",
    "    else:\n",
    "        print 'Failed delete: %s' % delKey\n",
    "    return\n",
    "\n",
    "#delete key from bucket, no feedback\n",
    "def quickDeleteKey(delBucket,delKey):\n",
    "    riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).delete(delKey)\n",
    "    return\n",
    "\n",
    "#delete all keys in a bucket, no feedback  \n",
    "def quickDeleteAllKeys(delBucket):\n",
    "    for keys in  riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).stream_keys():\n",
    "        for delKey in keys:\n",
    "            quickDeleteKey(delBucket, delKey)      \n",
    "    print 'Done'\n",
    "    return\n",
    "\n",
    "#delete all keys in a bucket, with feedback\n",
    "def deleteAllKeys(delBucket):\n",
    "    delList = []\n",
    "    for keys in  riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).stream_keys():\n",
    "        for delKey in keys:\n",
    "            deleteKey(delBucket, delKey)\n",
    "            delList.append(delKey)\n",
    "    return delList\n",
    "\n",
    "#get all key value pairs from a bucket\n",
    "def getAllKV(myBucket):\n",
    "    myData = {}\n",
    "    riak_bucket = riak.RiakClient(pb_port=8087, protocol='pbc').bucket(myBucket)\n",
    "    for keys in riak_bucket.stream_keys():\n",
    "        for key in keys:\n",
    "            tempData = riak_bucket.get(key).data\n",
    "            #print('Key: %s Value: %s' % (key, tempData))\n",
    "            myData[key] = tempData\n",
    "    return myData\n",
    "\n",
    "#get single value for a key in a bucket\n",
    "def getValue(myBucket, myKey):\n",
    "    myVal = json.loads(riak.RiakClient(pb_port=8087, protocol='pbc').bucket(myBucket).get(myKey).data)\n",
    "    return myVal\n",
    "\n",
    "#Take a tuple of tuples in and return something\n",
    "def pairAnalysis(pairTuple, ndays, beginDay = 0, zThresh = 2, critLevel = '5%'):\n",
    "    \n",
    "    #pair tuple looks like ([tickerA, [data]],[tickerB,[data]])\n",
    "    #input is assumed to be same length and sorted by date with most recent date first\n",
    "    \n",
    "    #unwrap first stock ticker and data\n",
    "    stockA = pairTuple[0]\n",
    "    stockAData = list(stockA[1])\n",
    "    \n",
    "    #unwrap the data for stockA\n",
    "    stockADates = [x[2] for x in stockAData]\n",
    "    stockAClose = [x[0] for x in stockAData]\n",
    "    stockAVolume = [x[1] for x in stockAData]\n",
    "    \n",
    "    #unwrap second stock ticker and data\n",
    "    stockB = pairTuple[1]\n",
    "    stockBData = list(stockB[1])\n",
    "   \n",
    "    #unwrap stockB data\n",
    "    stockBDates = [x[2] for x in stockBData]\n",
    "    stockBClose = [x[0] for x in stockBData]\n",
    "    stockBVolume = [x[1] for x in stockBData]\n",
    "    \n",
    "    pair = pairCalc(stockAClose,stockBClose,beginDay,ndays, zThresh, critLevel)\n",
    "    #if pair tradeable, add some more info\n",
    "    if type(pair) is list:\n",
    "            pair.insert(0,stockADates[beginDay])\n",
    "            pair.insert(0,stockB[0])\n",
    "            pair.insert(0,stockA[0])\n",
    "            return pair\n",
    "    else:\n",
    "        return pair\n",
    "\n",
    "def pairCalc(tsA,tsB,beginDay,ndays,zThresh = 2, critLevel = '5%'):\n",
    "    \n",
    "    #perform engle granger cointegration test\n",
    "    coint = eg_test(tsA[beginDay:ndays],tsB[beginDay:ndays], critLevel)\n",
    "    \n",
    "    #if coint return 0, then the two timeseries are not cointegrated\n",
    "    if (coint[0] != 1):\n",
    "        return 0\n",
    "    #else calculate stuff\n",
    "    else:\n",
    "        #signal = tsA[0] - beta*tsB[0] - CONSTANT = normal gaussian with mean 0\n",
    "        signal = [a - coint[1][1]*b - coint[1][0] for a in tsA[beginDay:ndays] for b in tsB[beginDay:ndays]]\n",
    "        sigMean = numpy.mean(signal)\n",
    "        sigStd = numpy.std(signal)\n",
    "        #zscore is (signal - signalMean) / signalStd\n",
    "        zscore = (signal[beginDay] - sigMean)/sigStd\n",
    "        #if current zscore is larger than zThresh, possible pair to trade\n",
    "        if abs(zscore) > zThresh:\n",
    "            return [tsA[0],tsB[0], zscore, coint[1][1], sigMean, sigStd]\n",
    "    return 1\n",
    "\n",
    "#write tradeable pair back into riak\n",
    "def writePairs(pairList):\n",
    "    \n",
    "    #tradeable pairs are lists\n",
    "    tradeable = [x for x in pairList if type(x) is list]\n",
    "    \n",
    "    for pair in tradeable:\n",
    "        writeSinglePair(pair)\n",
    "    \n",
    "    #return a list of written pairs\n",
    "    return tradeable\n",
    "       \n",
    "#write a signle pair to riak\n",
    "#assumes pair is in a list of values\n",
    "def writeSinglePair(pair):\n",
    "    \n",
    "    rc = RiakClient(pb_port=8087, protocol='pbc')\n",
    "    bucket = rc.bucket('tradeEntries')\n",
    "    \n",
    "    #create key value pairs to stock in riak\n",
    "    key = str(str(pair[0])+ '_' + str(pair[1]))\n",
    "    val = {'StockA': pair[0], \\\n",
    "                'StockB': pair[1], \\\n",
    "                'Date': pair[2],\\\n",
    "                'CloseA': pair[3], \\\n",
    "                'CloseB': pair[4], \\\n",
    "                'ZScore': pair[5],\\\n",
    "                'Beta': pair[6],\\\n",
    "                'SignalMean': pair[7],\\\n",
    "                'SignalSD': pair[8]}\n",
    "    myDate = pair[2].split('-')\n",
    "    obj = RiakObject(rc, bucket, key)\n",
    "        \n",
    "    #add 2i tags\n",
    "    obj.add_index(\"stocka_bin\", str(pair[0]))\n",
    "    obj.add_index(\"stockb_bin\", str(pair[3]))\n",
    "    obj.add_index(\"year_int\", int(myDate[0]))\n",
    "    obj.add_index(\"month_int\", int(myDate[1]))\n",
    "    obj.add_index(\"day_int\", int(myDate[2]))\n",
    "    obj.content_type = 'text/json'\n",
    "    obj.data = val\n",
    "    obj.data = json.dumps(val)\n",
    "    #store\n",
    "    obj.store()\n",
    "    \n",
    "    #return a list of written pairs\n",
    "    return pair   \n",
    "    \n",
    "#return 1 if the two series are cointegrated and 0 otherwise, return regression parameters either way\n",
    "#assumes y,x are aligned and of equal length\n",
    "#critLevel can be '1%', '5%' or '10%'\n",
    "def eg_test(y, x,critLevel):\n",
    "    \n",
    "    #must add a constant row of 1s to dependent variable, its a multidimensional regression thing\n",
    "    x = stat.add_constant(x)\n",
    "    #get residuals\n",
    "    result = stat.OLS(y, x).fit()\n",
    "    #regression parameters, slope and intercept\n",
    "    regPar = result.params\n",
    "    #run augmented dickey fuller test of stationarity of residuals\n",
    "    #null hypothesis is stationaity of timeseries\n",
    "    adfResults = ts.adfuller(result.resid, maxlag=0, regression='c', autolag=None, store=False, regresults=True)\n",
    "    #test statistic\n",
    "    tstat = adfResults[0]\n",
    "    #critical value\n",
    "    critVal = adfResults[2][critLevel]\n",
    "    #if test stat is less than critical value, accept null hyptohesis of stationarity\n",
    "    if tstat < critVal:\n",
    "        return [1,regPar]\n",
    "    else:\n",
    "        return [0,regPar]\n",
    "\n",
    "#get all values for a stock from riak  \n",
    "#return close,volume,date values in a list of list\n",
    "def riakGetStock(searchVal):\n",
    "    myData = []\n",
    "    myBucket = RiakClient(pb_port=8087, protocol='pbc').bucket('stocks')\n",
    "    for key in myBucket.get_index('ticker_bin', searchVal): # get all from 2002 to 2012\n",
    "        value = json.loads(myBucket.get(key).data)\n",
    "        myData.append([(value['CLOSE']), (value['VOLUME']), str(value['DATE'])])\n",
    "    return myData\n",
    "\n",
    "#quick function to sort a list of list on the inner list 3 value(date)\n",
    "def mySort(s):\n",
    "    sortList = list(s)\n",
    "    sortList.sort(key=lambda x: x[2], reverse=True)\n",
    "    return sortList\n",
    "\n",
    "#cut length of time series to n\n",
    "def myFilter(s,n):\n",
    "    return list(s[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
