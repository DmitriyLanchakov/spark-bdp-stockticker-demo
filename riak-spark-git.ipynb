{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grab data from google finance api\n",
    "#Daily stock data will be grab for all tickers in tickerFile from today until lastDay\n",
    "#and written to riak bucket 'stocks'\n",
    "\n",
    "today = datetime(datetime.now().year, datetime.now().month, datetime.now().day)\n",
    "lastDay = datetime(2000,1,1)\n",
    "tickerFile = 'NYSE.txt'\n",
    "dataSource = 'google'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(tickerFile,sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickers = list(stocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataGet = sc.parallelize(tickers[0:100])\n",
    "dataGet.map(lambda x: getDataByTicker(x,dataSource,lastDay,today)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filtering the data\n",
    "#1:Split into a tuple (TICKER, [CLOSE,VOLUME, DATE])\n",
    "#2:Group by ticker\n",
    "#3:Filter out all stocks with less than minDays days of data\n",
    "#and all stocks with a single day volume of less than minVol\n",
    "#4:Sort the data by date with the most recent day first\n",
    "#5:Cut the data to length minDays\n",
    "\n",
    "minVol = 20000\n",
    "minDays = 2000\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "d = sc.parallelize(tickers[0:100]).map(lambda x: (x, riakGetStock(x)))\\\n",
    "    .filter(lambda x: len(x[1]) > minDays)\\\n",
    "    .filter(lambda x: numpy.mean([i[1] for i in x[1]]) > minVol)\\\n",
    "    .map(lambda x: (x[0],mySort(x[1])))\\\n",
    "    .map(lambda x: (x[0],myFilter(x[1],minDays))).cache()\n",
    "\n",
    "pairs = d.cartesian(d)\\\n",
    "    .map(lambda x: pairAnalysis(x,200))\\\n",
    "    .collect()\n",
    "    \n",
    "written = writePairs(pairs)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import time\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import riak\n",
    "import urllib2\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from pandas.io.data import DataReader\n",
    "import riak\n",
    "from riak import RiakClient, RiakNode, RiakObject\n",
    "import numpy as np\n",
    "import statsmodels.api as stat\n",
    "import statsmodels.tsa.stattools as ts\n",
    "\n",
    "def getData(tickerFile, dataSource, start, end):\n",
    "\n",
    "    rc = RiakClient(pb_port=8087, protocol='pbc')\n",
    "    added = []\n",
    "    notAdded = []\n",
    "    stock = pd.read_csv(tickerFile,sep='\\t',header=None)\n",
    "\n",
    "    #loop over all stock tickers\n",
    "    for i in range(0,len(stock.head(100))):\n",
    "        #get daily data for each ticker\n",
    "        gtemp = pd.DataFrame()\n",
    "        bucket = rc.bucket('stocks')\n",
    "        try:\n",
    "            gtemp = DataReader(stock.ix[i,0],  dataSource, start, end)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #didnt get any data\n",
    "        if len(gtemp) == 0:\n",
    "            #print(str(i) + ': ' + str(stock.ix[i,0]) + ' : No Data : ' + str((float(i)*100)/len(stock)))\n",
    "            notAdded.append(stock.ix[i,0])\n",
    "        #got data\n",
    "        else:\n",
    "            #print(str(i) + ': ' + str(stock.ix[i,0]) + ' : ' + str(len(gtemp)) + ' :' + str(float(i)/len(stock)))\n",
    "            added.append(stock.ix[i,0])\n",
    "            \n",
    "            for j in range(0,len(gtemp.index)):\n",
    "            \n",
    "                #upload json to Riak Bucket\n",
    "                date = gtemp.index[j].date()\n",
    "                riakKey = str(stock.ix[i,0]) + '_' + str(date)\n",
    "                riakVal = {'OPEN': gtemp.values[j,0], \\\n",
    "                           'HIGH': gtemp.values[j,1], \\\n",
    "                           'LOW': gtemp.values[j,2], \\\n",
    "                           'CLOSE': gtemp.values[j,3], \\\n",
    "                           'VOLUME': gtemp.values[j,4],\\\n",
    "                           'DATE': str(date),\\\n",
    "                           'TICKER': str(stock.ix[i,0])}\n",
    "                \n",
    "                obj = RiakObject(rc, bucket, riakKey)\n",
    "                \n",
    "                obj.add_index(\"ticker_bin\", str(stock.ix[i,0]))\n",
    "                obj.add_index(\"year_int\", int(date.year))\n",
    "                obj.add_index(\"month_int\", int(date.month))\n",
    "                obj.add_index(\"day_int\", int(date.day))\n",
    "                \n",
    "                obj.content_type = 'text/json'\n",
    "                #obj.data = riakVal\n",
    "                obj.data = json.dumps(riakVal)\n",
    "                obj.store()\n",
    "\n",
    "    return added, notAdded\n",
    "\n",
    "#start is furthest day back and end is closest to today\n",
    "def getDataByTicker(ticker, dataSource, start, end):\n",
    "\n",
    "    rc = RiakClient(pb_port=8087, protocol='pbc')\n",
    "    #get daily data for each ticker\n",
    "    gtemp = pd.DataFrame()\n",
    "    bucket = rc.bucket('stocks')\n",
    "    try:\n",
    "        gtemp = DataReader(ticker,  dataSource, start, end)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        #didnt get any data\n",
    "    if len(gtemp) == 0:\n",
    "        return 0\n",
    "    #got data\n",
    "    else:\n",
    "        \n",
    "        for j in range(0,len(gtemp.index)):\n",
    "            \n",
    "            #upload json to Riak Bucket\n",
    "            date = gtemp.index[j].date()\n",
    "            riakKey = str(ticker + '_' + str(date))\n",
    "            riakVal = {'OPEN': gtemp.values[j,0],\\\n",
    "                        'HIGH': gtemp.values[j,1],\\\n",
    "                        'LOW': gtemp.values[j,2], \\\n",
    "                        'CLOSE': gtemp.values[j,3], \\\n",
    "                        'VOLUME': gtemp.values[j,4],\\\n",
    "                        'DATE': str(date),\\\n",
    "                        'TICKER': str(ticker)}\n",
    "                \n",
    "            obj = RiakObject(rc, bucket, riakKey)\n",
    "                \n",
    "            obj.add_index(\"ticker_bin\", str(ticker))\n",
    "            obj.add_index(\"year_int\", int(date.year))\n",
    "            obj.add_index(\"month_int\", int(date.month))\n",
    "            obj.add_index(\"day_int\", int(date.day))\n",
    "                \n",
    "            obj.content_type = 'text/json'\n",
    "            #obj.data = riakVal\n",
    "            obj.data = json.dumps(riakVal)\n",
    "            obj.store()\n",
    "\n",
    "    return len(gtemp.index)\n",
    "\n",
    "def riakSearchData(searchBucket, searchTerm, searchVal1, searchVal2):\n",
    "    myData = {}\n",
    "    myBucket = RiakClient(pb_port=8087, protocol='pbc').bucket(searchBucket)\n",
    "    if searchVal2 != None:\n",
    "        for key in myBucket.get_index(searchTerm, searchVal1, searchVal2): # get all from 2002 to 2012\n",
    "            myData[key] = json.loads(myBucket.get(key).data)\n",
    "    else:\n",
    "        for key in myBucket.get_index(searchTerm, searchVal1): # get all from 2002 to 2012\n",
    "            myData[key] = json.loads(myBucket.get(key).data)\n",
    "    return myData\n",
    "\n",
    "def storeKV(myBucket, myKey, myVal):\n",
    "    riak.RiakClient(pb_port=8087, protocol='pbc').bucket(myBucket).new(myKey, data = myVal).store()\n",
    "    return\n",
    "\n",
    "def deleteKey(delBucket, delKey):\n",
    "    riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).delete(delKey)\n",
    "    if riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).get(delKey).data == None:\n",
    "        print 'Successful delete: %s' % delKey\n",
    "    else:\n",
    "        print 'Failed delete: %s' % delKey\n",
    "    return\n",
    "\n",
    "def quickDeleteKey(delBucket,delKey):\n",
    "    riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).delete(delKey)\n",
    "    return\n",
    "    \n",
    "def quickDeleteAllKeys(delBucket):\n",
    "    for keys in  riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).stream_keys():\n",
    "        for delKey in keys:\n",
    "            quickDeleteKey(delBucket, delKey)\n",
    "            \n",
    "    print 'Done'\n",
    "    return\n",
    "\n",
    "def deleteAllKeys(delBucket):\n",
    "\n",
    "    for keys in  riak.RiakClient(pb_port=8087, protocol='pbc').bucket(delBucket).stream_keys():\n",
    "        for delKey in keys:\n",
    "            deleteKey(delBucket, delKey)\n",
    "    return\n",
    "\n",
    "def getAllKV(myBucket):\n",
    "    myData = {}\n",
    "    riak_bucket = riak.RiakClient(pb_port=8087, protocol='pbc').bucket(myBucket)\n",
    "    for keys in riak_bucket.stream_keys():\n",
    "        for key in keys:\n",
    "            tempData = riak_bucket.get(key).data\n",
    "            print('Key: %s Value: %s' % (key, tempData))\n",
    "            myData[key] = tempData\n",
    "    return myData\n",
    "\n",
    "def getValue(myBucket, myKey):\n",
    "    myVal = json.loads(riak.RiakClient(pb_port=8087, protocol='pbc').bucket(myBucket).get(myKey).data)\n",
    "    return myVal\n",
    "\n",
    "#Take a tuple of tuples in and return something\n",
    "def pairAnalysis(pairTuple, ndays):\n",
    "    \n",
    "    stockA = pairTuple[0]\n",
    "    stockAData = list(stockA[1])\n",
    "    \n",
    "    \n",
    "    stockADates = [x[2] for x in stockAData]\n",
    "    stockAClose = [x[0] for x in stockAData]\n",
    "    stockAVolume = [x[1] for x in stockAData]\n",
    "    \n",
    "    stockB = pairTuple[1]\n",
    "    stockBData = list(stockB[1])\n",
    "   \n",
    "    \n",
    "    stockBDates = [x[2] for x in stockBData]\n",
    "    stockBClose = [x[0] for x in stockBData]\n",
    "    stockBVolume = [x[1] for x in stockBData]\n",
    "    \n",
    "    if stockADates[0:ndays] != stockBDates[0:ndays]:\n",
    "        return 1\n",
    "    else:\n",
    "        coint = eg_test(stockAClose[0:ndays],stockBClose[0:ndays])\n",
    "        #print coint\n",
    "        if (coint[0] != 1):\n",
    "            return 2\n",
    "        else:\n",
    "            signal = [a - coint[1][1]*b - coint[1][0] for a in stockAClose[0:ndays] for b in stockBClose[0:ndays]]\n",
    "            sigMean = numpy.mean(signal)\n",
    "            sigStd = numpy.std(signal)\n",
    "            zscore = (signal[len(signal)-1] - sigMean)/sigStd\n",
    "            if abs(zscore) > 1:\n",
    "                return [stockA[0], stockAClose[0], stockB[0], stockBClose[0], zscore, coint[1][1], sigMean, sigStd, stockADates[0]]\n",
    "    return 3\n",
    "\n",
    "def writePairs(pairList):\n",
    "    \n",
    "    tradeable = [x for x in pairList if type(x) is list]\n",
    "    \n",
    "    rc = RiakClient(pb_port=8087, protocol='pbc')\n",
    "    bucket = rc.bucket('tradeEntries')\n",
    "    for pair in tradeable:\n",
    "        \n",
    "        key = str(str(pair[0])+ '_' + str(pair[2]))\n",
    "        val = {'StockA': pair[0], \\\n",
    "                   'CloseA': pair[1], \\\n",
    "                   'StockB': pair[2], \\\n",
    "                   'CloseB': pair[3], \\\n",
    "                   'ZScore': pair[4],\\\n",
    "                   'Beta': pair[5],\\\n",
    "                   'SignalMean': pair[6],\\\n",
    "                   'SignalSD': pair[7],\\\n",
    "                   'Date': pair[8]}\n",
    "        myDate = pair[8].split('-')\n",
    "        obj = RiakObject(rc, bucket, key)\n",
    "        obj.add_index(\"stocka_bin\", str(pair[0]))\n",
    "        obj.add_index(\"stockb_bin\", str(pair[3]))\n",
    "        obj.add_index(\"year_int\", int(myDate[0]))\n",
    "        obj.add_index(\"month_int\", int(myDate[1]))\n",
    "        obj.add_index(\"day_int\", int(myDate[2]))\n",
    "        obj.content_type = 'text/json'\n",
    "        obj.data = val\n",
    "        obj.data = json.dumps(val)\n",
    "        obj.store()\n",
    "        \n",
    "    return tradeable\n",
    "       \n",
    "#return 1 if the two series are cointegrated and 0 otherwise\n",
    "def eg_test(y, x):\n",
    "    \n",
    "    if len(y) == 0 | len(x) == 0:\n",
    "        return [2,0,0]\n",
    "    \n",
    "    x = stat.add_constant(x)\n",
    "    result = stat.OLS(y, x).fit()\n",
    "    regPar = result.params\n",
    "    adfResults = ts.adfuller(result.resid, maxlag=0, regression='c', autolag=None, store=False, regresults=True)\n",
    "    tstat = adfResults[0]\n",
    "    critVal = adfResults[2]['1%']\n",
    "    \n",
    "    if tstat < critVal:\n",
    "        return [1,regPar]\n",
    "    else:\n",
    "        return [0,regPar]\n",
    "    \n",
    "def riakGetStock(searchVal):\n",
    "    myData = []\n",
    "    myBucket = RiakClient(pb_port=8087, protocol='pbc').bucket('stocks')\n",
    "    for key in myBucket.get_index('ticker_bin', searchVal): # get all from 2002 to 2012\n",
    "        value = json.loads(myBucket.get(key).data)\n",
    "        myData.append([(value['CLOSE']), (value['VOLUME']), str(value['DATE'])])\n",
    "    return myData\n",
    "\n",
    "def mySort(s):\n",
    "    sortList = list(s)\n",
    "    sortList.sort(key=lambda x: x[2], reverse=True)\n",
    "    return sortList\n",
    "\n",
    "def myFilter(s,n):\n",
    "    return list(s[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
